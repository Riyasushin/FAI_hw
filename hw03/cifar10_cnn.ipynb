{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "RiJoshin, 2400013201;\n",
    "\n",
    "人工智能基础第三次作业的实现，为方便图像显示与分模块修改\n",
    "\n",
    "起于2025-04-03\n",
    "\n",
    "\n",
    "## 第二课作业\n",
    "用pytorch实现卷积神经网络，对cifar10数据集进行分类\n",
    "要求:\n",
    "1. 使用pytorch的nn.Module和Conv2d等相关的API实现卷积神经网络\n",
    "2. 使用pytorch的DataLoader和Dataset等相关的API实现数据集的加载\n",
    "3. 修改网络结构和参数，观察训练效果\n",
    "4. 使用数据增强，提高模型的泛化能力\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "# plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "hyperparameters = {\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs': 100,\n",
    "    'early_stop_patience': 15\n",
    "}\n",
    "EARLY_STOP = True\n",
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 自定义高斯噪声变换\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.1, p=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if np.random.rand() < self.p:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        return tensor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1}, p={2})'.format(self.mean, self.std, self.p)\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # 归一化\n",
    "])\n",
    "\n",
    "# 数据增强的数据预处理方式\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # 随机缩放裁剪\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # 颜色扰动\n",
    "    # transforms.RandomRotation(15),  # 小幅旋转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3)),  # 随机擦除\n",
    "    # AddGaussianNoise(mean=0., std=0.1, p=0.5),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # 归一化\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_training_progress(train_acc_list, train_loss_list, test_acc_list,\n",
    "                                hyperparameters=None, model_architecture=None, \n",
    "                                description=\"\", save_dir=\"training_logs\", \n",
    "                                show_plot=True):\n",
    "    \"\"\"\n",
    "    可视化训练过程的准确率和损失，并自动保存图表和相关参数。\n",
    "    \n",
    "    参数:\n",
    "    - train_acc_list: 每个epoch的训练准确率列表\n",
    "    - train_loss_list: 每个epoch的训练损失列表\n",
    "    - test_acc_list: 每个epoch的测试准确率列表\n",
    "    - hyperparameters: 超参数字典\n",
    "    - model_architecture: 模型架构描述\n",
    "    - description: 实验描述\n",
    "    - save_dir: 保存图表和日志的目录\n",
    "    - show_plot: 是否显示图表\n",
    "    \"\"\"\n",
    "    \n",
    "    # 创建保存目录\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # 生成唯一的文件名\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    random_str = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))\n",
    "    file_prefix = f\"{timestamp}_{random_str}\"\n",
    "    \n",
    "    # 创建图表\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), constrained_layout=True)\n",
    "    \n",
    "    # 绘制准确率\n",
    "    epochs = np.arange(1, len(train_acc_list) + 1)\n",
    "    ax1.plot(epochs, train_acc_list, 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax1.plot(epochs, test_acc_list, 'r--', label='Validation Accuracy', linewidth=2)\n",
    "    ax1.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epochs', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    # 绘制损失\n",
    "    ax2.plot(epochs, train_loss_list, 'g-', label='Training Loss', linewidth=2)\n",
    "    ax2.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epochs', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    # 添加描述信息\n",
    "    fig.suptitle(f'Training Progress - {description}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 保存图表\n",
    "    plot_filename = os.path.join(save_dir, f\"{file_prefix}_training_progress.png\")\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # 保存超参数和模型架构\n",
    "    info_filename = os.path.join(save_dir, f\"{file_prefix}_training_info.txt\")\n",
    "    with open(info_filename, 'w') as f:\n",
    "        f.write(f\"Training Progress Summary - {description}\\n\")\n",
    "        f.write(f\"Timestamp: {timestamp}\\n\\n\")\n",
    "        \n",
    "        if hyperparameters:\n",
    "            f.write(\"Hyperparameters:\\n\")\n",
    "            for key, value in hyperparameters.items():\n",
    "                f.write(f\"  {key}: {value}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        if model_architecture:\n",
    "            f.write(\"Model Architecture:\\n\")\n",
    "            f.write(f\"{model_architecture}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"Training Accuracy: \\n\")\n",
    "        f.write(f\"{train_acc_list}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Training Loss: \\n\")\n",
    "        f.write(f\"{train_loss_list}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Validation Accuracy: \\n\")\n",
    "        f.write(f\"{test_acc_list}\\n\\n\")\n",
    "\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"Training progress visualization saved to: {plot_filename}\")\n",
    "    print(f\"Training information saved to: {info_filename}\")\n",
    "    # return plot_filename, info_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据集\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# 定义数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train\n",
    "# Mean: tensor([-0.3301, -0.3376, -0.3116])\n",
    "# Std: tensor([1.3983, 1.3937, 1.4152])\n",
    "\n",
    "# test\n",
    "# Mean: tensor([0.0139, 0.0147, 0.0194])\n",
    "# Std: tensor([1.2192, 1.2181, 1.3015])\n",
    "\n",
    "# # 初始化变量\n",
    "# mean = 0.0\n",
    "# std = 0.0\n",
    "\n",
    "# # 计算均值\n",
    "# for images, _ in test_loader:\n",
    "#     batch_samples = images.size(0)  # 当前批次的样本数量\n",
    "#     images = images.view(batch_samples, images.size(1), -1)  # 展平每个通道\n",
    "#     mean += images.mean(2).sum(0)  # 按通道计算均值并累加\n",
    "\n",
    "# mean = mean / len(test_loader.dataset)  # 计算全局均值\n",
    "\n",
    "# # 计算标准差\n",
    "# for images, _ in test_loader:\n",
    "#     batch_samples = images.size(0)\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "#     std += ((images - mean.unsqueeze(1)) ** 2).sum([0, 2])  # 按通道计算方差并累加\n",
    "\n",
    "# std = torch.sqrt(std / (len(test_loader.dataset) * 32 * 32))  # 计算全局标准差\n",
    "\n",
    "# print(\"Mean:\", mean)\n",
    "# print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal My Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义模型\n",
    "class Net(nn.Module):\n",
    "    '''\n",
    "    定义卷积神经网络,3个卷积层,2个全连接层\n",
    "    '''\n",
    "    def __init__(self, height, width):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.image_height = height\n",
    "        self.image_width = width\n",
    "\n",
    "        # 先写死，后面改成根据输入参数构建网络维度的 TODO 最多5层\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1), # 3, H, W -> 32, H, W\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1), # 32, H/2, W/2 -> 64, H/2, W/2\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1), # 64, H/4, W/4 -> 128, H/4, W/4\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1), # 128, H/8, W/8 -> 256, H/8, W/8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1), # 256, H/16, W/16 -> 512, H/16, W/16\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * (height // 32) * (width // 32), 4096), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 10),\n",
    "            nn.Softmax(dim=1) # 10 -> 10\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        '''\n",
    "        Args:\n",
    "            x: tensor, shape [batch_size, 3, H, W]\n",
    "        '''\n",
    "        res = self.conv(x)\n",
    "        if DEBUG:\n",
    "            print(\"conv output shape: \", res.shape)\n",
    "        res = res.view(res.size(0), -1)\n",
    "        if DEBUG:\n",
    "            print(\"conv flatten output shape: \", res.shape)\n",
    "        res = self.fc(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 2048),  # 输入维度调整为 512*1*1，因为 CIFAR-10 的图像大小是 32x32\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            # nn.Linear(1024, 4096),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ResNet\n",
    "class BasicBlockForResNet(nn.Module):\n",
    "    expansion = 1 # in_channel = expansion * out_channel\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlockForResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) # !!!!!! TODO important\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "\n",
    "        self.shortcut = nn.Sequential() \n",
    "        if stride != 1 or in_channels != self.expansion * out_channels: # TODO\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels,  self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True) # inplace=True, 直接在原来的内存上进行操作，节省内存开销\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x))) \n",
    "        out = self.bn2(self.conv2(out)) \n",
    "        out += self.shortcut(x) # 残差连接\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetTest(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetTest, self).__init__()\n",
    "\n",
    "\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Kaiming初始化 # TODO 初始化，来自PPT    \n",
    "        # 权重初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        # 构建多个残差块\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x))) \n",
    "        out = self.layer1(out) \n",
    "        out = self.layer2(out) \n",
    "        out = self.layer3(out) \n",
    "        out = self.layer4(out)  \n",
    "        out = self.avg_pool(out) \n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model的实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 实例化模型\n",
    "model = VGG16()\n",
    "# model = ResNetTest(BasicBlockForResNet, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_mlu = False # 爱了，喜欢这个判断\n",
    "try:\n",
    "    use_mlu = torch.mlu.is_available()\n",
    "except:\n",
    "    use_mlu = False\n",
    "\n",
    "if use_mlu:\n",
    "    device = torch.device('mlu:0')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(f'MLU is not available, use {device} instead.')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# init model\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择lossFunction 以及 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['learning_rate'], weight_decay=5e-4) ## TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch):\n",
    "    '''\n",
    "    Args:\n",
    "        epoch (int): 当前epoch次数\n",
    "    Returns:\n",
    "        并非list\n",
    "        accuracie (Tensor): 本轮最后次统计的正确率\n",
    "        losses     (Tensor): 同, loss\n",
    "    '''\n",
    "    # 训练模式\n",
    "    model.train()\n",
    "    accuracies = None\n",
    "    losses = None\n",
    "    # 使用 tqdm 包装数据加载器，显示训练进度\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{hyperparameters['num_epochs']}\", unit=\"batch\")\n",
    "    \n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (outputs.argmax(1) == labels).float().mean()\n",
    "\n",
    "        # 打印训练信息\n",
    "        if (i + 1) % 100 == 0:\n",
    "            accuracies = accuracy.item()\n",
    "            losses = loss.item()\n",
    "            # 更新进度条信息\n",
    "            progress_bar.set_postfix({\n",
    "                \"Loss\": f\"{loss.item():.4f}\",\n",
    "                \"Accuracy\": f\"{accuracy.item():.4f}\"\n",
    "            })\n",
    "\n",
    "    return accuracies, losses\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(epoch):\n",
    "    '''\n",
    "    没有传参数model, 把model当全局变量用了, 这样写的少些(其实是为了改回py文件时候好改, 只用复制粘贴就行, 不想起新名字折腾变量声明域了)\n",
    "    Returns:\n",
    "        test_acc (double): 测试正确率\n",
    "    '''\n",
    "    # 测试模式\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_acc = correct / total\n",
    "\n",
    "        print( f'    Epoch {epoch + 1}/{ hyperparameters[\"num_epochs\"] } TestAccuracy: {test_acc:.2f}' )\n",
    "        return test_acc\n",
    "        # test_log = 'Test Accuracy of the model on the 10000 test images: {} %'.format(test_acc)\n",
    "        # print(test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train的主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0.0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "epoch_train_acc_list = []\n",
    "epoch_train_loss_list = []\n",
    "epoch_test_acc_list = []\n",
    "# 训练模型\n",
    "for epoch in range(hyperparameters['num_epochs']):\n",
    "    train_acc, train_loss = train_model(epoch)\n",
    "    test_acc = test_model(epoch)\n",
    "\n",
    "    # early stopping\n",
    "    if EARLY_STOP:\n",
    "        if (test_acc > best_accuracy):\n",
    "            best_accuracy = test_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"Early stopping counter: {counter}\")\n",
    "            if counter > hyperparameters['early_stop_patience']:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    \n",
    "    epoch_train_acc_list.append(train_acc)\n",
    "    epoch_train_loss_list.append(train_loss)\n",
    "    epoch_test_acc_list.append(test_acc)\n",
    "\n",
    "\n",
    "message = input(\"Please type some information here as mdescription:\\n    \")\n",
    "visualize_training_progress(\n",
    "        train_acc_list=epoch_train_acc_list,\n",
    "        train_loss_list=epoch_train_loss_list,\n",
    "        test_acc_list=epoch_test_acc_list,\n",
    "        hyperparameters=hyperparameters,\n",
    "        model_architecture=str(model),\n",
    "        description=message,\n",
    "        save_dir=\"training_logs\"\n",
    ")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

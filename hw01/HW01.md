# HW01



## 1ã€è¯·ç®€è¿°ä»€ä¹ˆæ˜¯è´å¶æ–¯å®šç†ï¼Œä»€ä¹ˆæ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡(MLE)ï¼Œä»€ä¹ˆæ˜¯æœ€å¤§åéªŒä¼°è®¡(MAP)ã€‚

##### è´å¶æ–¯å®šç†

è´å¶æ–¯å­¦æ´¾è®¤ä¸ºæ¦‚ç‡æ˜¯å¯¹ç»“æœçš„ä¿¡å¿µç¨‹åº¦

å…¬å¼æ˜¯

```math
P(A | B) = \frac{P(B|A)P(A)}{P(B)} \\
```

å…¶ä¸­ï¼š

- P(A|B) æ˜¯åéªŒæ¦‚ç‡ï¼Œè§‚å¯Ÿåˆ°å‡ºç°çš„ç°è±¡åï¼Œå¯¹å½“å‰æƒ…å†µä¸‹çš„æ¦‚ç‡å¤§æ›´æ–°
- P(B|A) æ˜¯ä¼¼ç„¶æ¦‚ç‡ï¼Œä¸åŒå‚æ•°ä¸‹yçš„å¯è§‚æµ‹æ•°æ®é›†ä¸­çš„å¯èƒ½æ€§
- P(A)æ˜¯å…ˆéªŒæ¦‚ç‡ï¼Œåœ¨è§‚å¯Ÿå‰å¯¹æ¦‚ç‡çš„çŒœæµ‹
- P(B) æ˜¯å½’ä¸€åŒ–å¸¸æ•°ï¼Œè®©æ€»å’Œä¸º1



##### MLE

- è®¤ä¸ºå‚æ•° $\theta$ ä¸ºä¸€ä¸ªå¸¸æ•°ï¼Œç›®çš„æ˜¯æ‰¾çš„è¿™ä¸ªç»“æœ$\theta$ s.t.:

  $$\theta_{MLE} = arg \underset{\theta}{max} P (B | \theta)$$

- å¯¹äºè¿™ä¸ªæ¦‚ç‡æ¨¡å‹çš„å‚æ•° $\theta$ ï¼Œæ±‚æœ€å¥½çš„ $\theta$ è®© å‡ºç°å¾—åˆ°çš„æ•°æ®çš„æ¦‚ç‡æœ€å¤§

```math
æ–¹ä¾¿äº›å–ln:lnP(X|\theta) = \sum lnP(x_i|\theta) \\
æ‰¾è¿™æ ·çš„å‚æ•° \theta è®© P(X|\theta)æœ€å¤§ ï¼ˆè¿™é‡Œçš„\theta ä»£æ‰€æœ‰ç›¸å…³çš„å‚æ•°ï¼‰
```

- é€‰æ‹©ä¸€ä¸ªæ¨¡å‹æ¥é€‚é…æ•°æ®æ—¶ï¼Œå®é™…ä¸Šæ˜¯åœ¨åšå‡ºä¸€ä¸ªå…³äºæ•°æ®å¯èƒ½çš„åº•å±‚è¿‡ç¨‹çš„å‡è®¾

- å‡è®¾æ•°æ®ç”Ÿæˆè¿‡ç¨‹æ˜¯ç”±æŸä¸ªåˆ†å¸ƒæ§åˆ¶çš„ï¼Œä¸æ˜¯é€‰æ‹©æŸä¸ªå‚æ•°çš„æ¦‚ç‡åˆ†å¸ƒ

##### MAP

- è®¤ä¸ºå‚æ•° $\theta$ä¹Ÿæ˜¯éšæœºå˜é‡ï¼Œå‡è®¾æœ‰å…ˆéªŒåˆ†å¸ƒ

- ç”¨ä¸€ä¸ªè®¾å¥½çš„å‚æ•°çš„è´å¡”åˆ†å¸ƒä½œä¸º $\theta$ çš„å…ˆéªŒåˆ†å¸ƒ $p(\theta)$ ï¼ˆå¯¹å‚æ•°è¿›è¡Œäº†åˆ†å¸ƒå»ºæ¨¡ï¼‰

  $$\theta_{MAP} = arg \underset{\theta}{max} P(B|\theta) P (\theta)$$
  
  
  



---

## 2ã€è®¾ğ‘‹~ğ‘($ğœ‡$, $ğœ^2$), $ğœ‡$, $ğœ^2$ä¸ºæœªçŸ¥å‚æ•°ï¼Œ$x_1, ğ‘¥_2, \dots, ğ‘¥_n$æ˜¯æ¥è‡ªğ‘‹çš„æ ·æœ¬å€¼ï¼Œæ±‚ğœ‡, ğœ!çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡é‡ã€‚ 

```math

\begin{array}{l}
F(\mu, \sigma^2) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x - \mu)^2}{2\sigma^2}} \\
\ln F = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln{\sigma^2} - \frac{1}{2\sigma^2} \sum_{i=1}^n(x_i-\mu)^2 \\
\text{å¯¹ }\mu\text{ æ±‚åå¯¼ï¼š}\\
\frac{1}{\sigma^2}\sum(x_i - \mu) = 0 \\
\text{å¯¹ }\sigma^2\text{ æ±‚åå¯¼ï¼š} \\
-\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\sum_{i=1}^n(x_i-\mu)^2 = 0\\
\textbf{äºæ˜¯å¾—åˆ°ç»“è®º:}\\


\end{array}

```

```math
\mu = \frac{\sum_{i=1}^n x_i}{n} \\
\sigma = \frac{\sum_{i=1}^n x_i^2 - n \times \mu^2}{n}\\
```



## 3ã€è¯·ç®€è¿°åˆ†ç±»é—®é¢˜ä¸å›å½’é—®é¢˜çš„ä¸»è¦åŒºåˆ«ã€‚

|          | åˆ†ç±»é—®é¢˜                          | å›å½’é—®é¢˜             |
| -------- | --------------------------------- | -------------------- |
| æ•°æ®ç»“æœ | ç¦»æ•£ï¼Œæ¯”å¦‚one-hot Vectorï¼Œ        | åˆ†å¸ƒåœ¨è¿ç»­çš„å®æ•°ç©ºé—´ |
| å¸¸ç”¨loss | CrossEntropyç­‰                    | æ–¹å·®ã€å‡æ–¹å·®ç­‰       |
|          | å…ˆé€šè¿‡softmaxï¼Œå¾—åˆ°æœ€å¤§æ¦‚ç‡ä¸ºé¢„æµ‹ | è¿æ¥ä¸€ä¸ªFCä½œä¸ºè¾“å‡ºå±‚ |



## 4ã€è¯·ç®€è¿°æœ‰ç›‘ç£å­¦ä¹ ä¸æ— ç›‘ç£å­¦ä¹ çš„ä¸»è¦åŒºåˆ«ã€‚

|            | æœ‰ç›‘ç£å­¦ä¹                 | æ— ç›‘ç£å­¦ä¹                         |
| ---------- | ------------------------- | --------------------------------- |
| æ•°æ®é›†å†…å®¹ | æ•°æ®éƒ½æœ‰label             | æ•°æ®æ²¡æœ‰label                     |
| å…¸å‹ä»»åŠ¡   | åˆ†ç±»ã€å›å½’                | èšç±»ã€é™ç»´ã€å¯†åº¦ä¼°è®¡              |
| ç»“æœé¢„æœŸ   | æ‹Ÿåˆå¾—åˆ°ä¸€ä¸ª$f(x)$è¿‘ä¼¼$y$ | å¸Œæœ›æœºå™¨è‡ªå·±å­¦ä¼šæŸäº›éšå«çš„pattern |

## 5ã€

> ç»™å®šæ•°æ® $D=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}$, ç”¨ä¸€ä¸ªçº¿æ€§æ¨¡å‹ä¼°è®¡æœ€æ¥è¿‘çœŸå® $\gamma_i$ (ground truth) çš„è¿ç»­æ ‡é‡ $Y$, $f(x_i)=w^Tx_i+b$, ä½¿å¾— $f(x_i)\approx y_i$.
>
> æ±‚æœ€ä¼˜ ($w^{*},b^{*}$) ä½¿å¾— $f(x_i)$ ä¸ $y_i$ ä¹‹é—´çš„å‡æ–¹è¯¯å·®æœ€å°ï¼š
>
> $$
> (w^*,b^*)=\arg\min_{(w,b)}\sum_{i=1}^n(f(x_i)-y_i)^2
> $$
>
> å¹¶è§£é‡Š $(w^*,b^*)$ ä½•æ—¶æœ‰ closed form è§£ï¼Œä½•æ—¶æ²¡æœ‰ closed form è§£ã€‚



æœ€å°äºŒä¹˜æ³•ï¼š

```math
(w^*, b^*) = arg \space min \sum_{i=1}^n (y_i - wx_i + b)^2\\

```



```math
\beta = 
\begin{bmatrix}
w_1 \\
w_2 \\
\vdots\\
w_{p-1} \\
b \\

\end{bmatrix}
```

æ¯ä¸ªæ•°æ®ä¸€è¡Œï¼Œæ¯ä¸ªæ ‡ç­¾ä¸€è¡Œï¼Œæ‹¿$x_i^{(p)} \equiv 1 $ 

```math
\textbf{A} =  
\begin{bmatrix}
X_1 \\
X_2 \\
\vdots \\
X_n
\end{bmatrix}
=
\begin{bmatrix}
x_1^{(1)} & \dots & x_1^{(p)} \\
\vdots & \ddots & \vdots \\
x_n^{(1)} & \dots & x_n^{(p)}\\
\end{bmatrix}
```

```math
\textbf{Y} =  
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}
```

æ‰¾ $\beta$ ä½¿å¾—: $$\hat{\beta} = arg \space \underset{\beta}{min} \frac{1}{n} \sum (X_i \beta - Y_i)^2 = arg \space \underset{\beta}{min} \frac{1}{n} (\textbf{A}\beta - \textbf{Y}^T(\textbf{A}\beta - \textbf{Y}) $$

næ˜¯å®šå€¼ï¼Œå¿½ç•¥

```math
\begin{aligned}
J(\beta) &= (\textbf{A}\beta - \textbf{Y}^T(\textbf{A}\beta - \textbf{Y})\\
&=\beta^{\textbf{T}} \textbf{A}^{T} \textbf{A} \beta-2 \beta^{\textbf{T}} \textbf{A}^{T} \textbf{Y}+\textbf{Y}^{T} \textbf{Y}\\

\end{aligned}
```

æ±‚åå¯¼å¾—å‡ºï¼š

```math
2\textbf{A}^T\textbf{A}\beta - 2\textbf{A}^T\textbf{Y} = 0 \\
\therefore \hat{\beta} = (\textbf{A}^T\textbf{A})^{-1}\textbf{A}^T\textbf{Y} , è‹¥ A å¯é€†
```

æ‰€ä»¥ï¼š

- Aä¸å¯é€†æ—¶æ—  closed formè§£
- Aå¯é€†æ—¶    æœ‰ closed formè§£







## 6ã€Ridge regression é—®é¢˜çš„è§£å…·æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Œä¸ºä»€ä¹ˆï¼ŸLasso é—®é¢˜çš„è§£å…·æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ

#### Ridge regression:

- $L1 = reg \times \sum| \beta_j | $ 
- å¯¹äºæ‰€æœ‰ç³»æ•°çš„æƒ©ç½šç¨‹åº¦ç›¸åŒï¼Œå¯¼è‡´ä¸€äº›ç³»æ•°ç›´æ¥ä¸º0
- äº§ç”Ÿç¨€ç–è§£

#### Lassoï¼š

- $$L2 =$$1Â²Â·LÂ² reg \times \sum \beta^2$$
- å¯¹ç»å¯¹å€¼å¤§çš„$\beta$æƒ©ç½šåŠ›åº¦æ›´å¤§
- ç³»æ•°å¹³æ»‘åœ°è¶‹è¿‘äº0ï¼Œæœ‰äº›$w$æ›´å°





## 7ã€è¯·ä» model functionã€loss functionã€optimization solution ä¸‰ä¸ªæ–¹é¢æ¯”è¾ƒ Linear regressionä¸ Logistic regression çš„å¼‚åŒã€‚

|                       | Linear regression                        | Logistic regression                  |
| --------------------- | ---------------------------------------- | ------------------------------------ |
| model function        | $$f(x) = W^T x + b$$                     | $$f(x)=\frac{1}{1 + e^{-W^Tx + b}}$$ |
| loss function         | MSEï¼Œè¡¡é‡$\hat{y}$å’Œ$y$çš„å·®å¼‚            | CrossEntropyï¼Œè¡¡é‡åˆ†å¸ƒçš„å·®å¼‚         |
| optimization solution | æœ€å°äºŒä¹˜æ³•ç›´æ¥ç®—å‚æ•°<br />æ¢¯åº¦ä¸‹é™è¿‘ä¼¼è§£ | ä¸€èˆ¬åªèƒ½æ¢¯åº¦ä¸‹é™è¿‘ä¼¼è§£               |



## 8ã€K-è¿‘é‚»åˆ†ç±»å™¨çš„è¶…å‚æ•°æ˜¯ä»€ä¹ˆï¼Ÿæ€ä¹ˆé€‰æ‹© K-è¿‘é‚»åˆ†ç±»å™¨çš„è¶…å‚æ•°ï¼Ÿ

#### è¶…å‚

- $k$ï¼šé‚»å±…ä¸ªæ•°
- è·ç¦»åº¦é‡æ–¹å¼ï¼šæ¬§æ°è·ç¦»ã€æ›¼å“ˆé¡¿è·ç¦»

#### æ€ä¹ˆé€‰æ‹©

äº¤å‰éªŒè¯æ³•

- æŠŠæ•°æ®é›†åˆ†ä¸ºnï¼ˆç»™å®šï¼‰ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ç”¨äºè®­ç»ƒï¼ˆ$70\% \sim 80\%$ï¼‰ï¼Œå¦ä¸€éƒ¨åˆ†ç”¨äºéªŒè¯($20\% \sim 30\%$)
- é€‰æ‹©éªŒè¯é›†accuracyæœ€å¤§çš„é‚£ä¸ª$k$.
